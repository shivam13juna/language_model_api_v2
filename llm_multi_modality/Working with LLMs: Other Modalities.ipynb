{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e40c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import textwrap\n",
    "\n",
    "\n",
    "#This is optional. I use VPN in my computer. Why I need this. \n",
    "import truststore\n",
    "truststore.inject_into_ssl()\n",
    "\n",
    "\n",
    "\n",
    "def pretty_print(*args):\n",
    "    text = \" \".join(str(arg) for arg in args)\n",
    "    try:\n",
    "        print(textwrap.fill(text, width=80))\n",
    "    except Exception as e:\n",
    "        print(text)  # fallback to normal print if text is not a string\n",
    "\n",
    "        \n",
    "\n",
    "load_dotenv('/Users/shivam13juna/Documents/scaler/iitr_classes/jan_2026/language_model_api_v2/openai_key.env')  # reads .env file in the current directory\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY not found! \"\n",
    "        \"Make sure you have a .env file with: OPENAI_API_KEY=sk-...\"\n",
    "    )\n",
    "\n",
    "pretty_print(\"API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9a5e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client ready.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "pretty_print(\"OpenAI client ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f9117e",
   "metadata": {},
   "source": [
    "# Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979fe9f",
   "metadata": {},
   "source": [
    "## Diff b/w Chat Completions and Responses API - Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eec181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completions output: A list comprehension is a concise way to create a new\n",
      "list by transforming items from an existing iterable, optionally filtering them.\n",
      "Basic syntax: - [expression for item in iterable] - You can add an optional\n",
      "condition: [expression for item in iterable if condition]  Examples: - Squares\n",
      "of numbers 0 through 9: squares = [x*x for x in range(10)] - Even numbers from 0\n",
      "to 19: evens = [n for n in range(20) if n % 2 == 0] - Uppercase words: upper =\n",
      "[s.upper() for s in [\"apple\",\"banana\"]] - Flattening a list of lists: flat = [c\n",
      "for sub in [[1,2],[3,4]] for c in sub]  Compared to a loop: - Traditional:\n",
      "squares = []   for x in range(10):       squares.append(x*x) - List\n",
      "comprehension does the same in one line.  Notes: - They’re great for simple\n",
      "transformations and filters, but can hurt readability if too complex. - They\n",
      "create a list in memory. If you want lazy evaluation, use a generator\n",
      "expression: (expression for item in iterable if condition) - You can also use\n",
      "dict/set comprehensions for other collection types.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# do the same with chat completions\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[\n",
    "\t\t{\"role\": \"system\", \"content\": \"You are a friendly Python tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is a list comprehension?\"}\n",
    "    ]\n",
    ")\n",
    "pretty_print(\"Chat Completions output:\", resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36bfb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API output: A list comprehension is a compact way to create a new list\n",
      "by applying an expression to each item in an iterable, optionally filtering\n",
      "items or nesting loops.  Common form: - Basic: [expression for item in iterable]\n",
      "- With a filter: [expression for item in iterable if condition] - With multiple\n",
      "loops: [expression for a in A for b in B]  Examples: - Squares: [x*x for x in\n",
      "range(10)] - Evens from 0–19: [x for x in range(20) if x % 2 == 0] - Pairs: [(i,\n",
      "j) for i in range(3) for j in range(2)]  Notes: - It’s equivalent to building a\n",
      "list with a for-loop, but shorter and often more readable. - If you don’t want\n",
      "to build a list in memory, you can use a generator expression: (expression for\n",
      "item in iterable).\n"
     ]
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a friendly Python tutor.\",\n",
    "    input=\"What is a list comprehension?\"\n",
    ")\n",
    "\n",
    "pretty_print(\"Responses API output:\", resp.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877c891",
   "metadata": {},
   "source": [
    "## Passing Multi Turn Conversation History to Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f6b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API output: Subjectively, many people point to these as not jerks:  -\n",
      "Keanu Reeves — widely described as gracious, humble, and generous. - Tom Hanks —\n",
      "known for warmth and decency in public appearances. - Dwayne “The Rock” Johnson\n",
      "— often praised for positivity and philanthropy.  Of course, public personas\n",
      "vary by viewer, but these are commonly viewed as pleasant, not jerky, figures.\n",
      "If you want someone from a specific field (music, sports, etc.), I can tailor\n",
      "suggestions.\n"
     ]
    }
   ],
   "source": [
    "input_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Why is Trump a jerk?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Some people are born that way.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Name a celebrity who is not a jerk.\"}\n",
    "]\n",
    "\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a very candid Journalist.\",\n",
    "    input=input_messages\n",
    ")\n",
    "\n",
    "pretty_print(\"Responses API output:\", resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d3de4",
   "metadata": {},
   "source": [
    "| Feature             | Chat Completions API                             | Responses API                                              |\n",
    "| ------------------- | ------------------------------------------------ | ---------------------------------------------------------- |\n",
    "| **Endpoint**        | `client.chat.completions.create()`               | `client.responses.create()`                                |\n",
    "| **Input format**    | `messages=[{\"role\": ..., \"content\": ...}]`       | `input=` (string or list of message dicts)                 |\n",
    "| **System prompt**   | `{\"role\": \"system\", \"content\": ...}` in messages | `instructions=` parameter (top-level)                      |\n",
    "| **Output access**   | `resp.choices[0].message.content`                | `resp.output_text`                                         |\n",
    "| **Multi-turn**      | Manually pass full message history each time     | `previous_response_id=resp.id` (server-side context)       |\n",
    "| **Developer role**  | Not supported (use `system`)                     | `{\"role\": \"developer\"}` for meta-instructions              |\n",
    "| **Vision input**    | `{\"type\": \"image_url\", \"image_url\": {...}}`      | `{\"type\": \"input_image\", \"image_url\": ...}`                |\n",
    "| **Reasoning / CoT** | Not natively supported                           | `reasoning={\"effort\": ..., \"summary\": ...}` built-in       |\n",
    "| **Response object** | `ChatCompletion` with `choices[]` list           | `Response` with `output[]` list and `output_text` shortcut |\n",
    "| **Streaming**       | `stream=True` yields `ChatCompletionChunk`       | `stream=True` yields server-sent events                    |\n",
    "| **Tool calls**      | Supported via `tools` param                      | Supported via `tools` param (same)                         |\n",
    "| **Model support**   | All chat models                                  | All chat models (newer, recommended going forward)         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd54a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API output: That’s a tricky question—“not a jerk” is pretty subjective\n",
      "and can flip with the camera on. If you’re asking for someone widely regarded as\n",
      "gracious or down-to-earth in public life, a few names people frequently bring up\n",
      "are Tom Hanks or Keanu Reeves. They’re often cited for kindness and humility,\n",
      "though there’s always room for different perspectives. Want me to pull a few\n",
      "examples with receipts (quotes, interviews, philanthropy) to back it up?\n"
     ]
    }
   ],
   "source": [
    "input_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Why is Trump a jerk?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Some people are born that way.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Name a celebrity who is not a jerk.\"}\n",
    "]\n",
    "\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a very candid Journalist.\",\n",
    "    input=input_messages, \n",
    "    reasoning={\"effort\": \"minimal\"}\n",
    ")\n",
    "\n",
    "pretty_print(\"Responses API output:\", resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5861fd92",
   "metadata": {},
   "source": [
    "link to Documentation\n",
    "\n",
    "[Chat Completions](https://developers.openai.com/api/reference/python/resources/chat/subresources/completions/methods/create)\n",
    "\n",
    "[Responses API](https://developers.openai.com/api/reference/python/resources/responses/methods/create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010cb836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d64030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be5796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543fc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cd938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923b4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
