{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cb4c0f9",
   "metadata": {},
   "source": [
    "### 1.2 Load Your API Key Securely\n",
    "\n",
    "We **never** hardcode API keys. Instead we keep them in a `.env` file and load them at runtime with `python-dotenv`. Treat your key like a password — if it leaks, anyone can run up charges on your account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e43f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import textwrap\n",
    "\n",
    "\n",
    "#This is optional. I use VPN in my computer. Why I need this. \n",
    "import truststore\n",
    "truststore.inject_into_ssl()\n",
    "\n",
    "\n",
    "\n",
    "def pretty_print(*args):\n",
    "    text = \" \".join(str(arg) for arg in args)\n",
    "    try:\n",
    "        print(textwrap.fill(text, width=80))\n",
    "    except Exception as e:\n",
    "        print(text)  # fallback to normal print if text is not a string\n",
    "\n",
    "        \n",
    "\n",
    "load_dotenv('/Users/shivam13juna/Documents/scaler/iitr_classes/llm_ref/openai_key.env')  # reads .env file in the current directory\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY not found! \"\n",
    "        \"Make sure you have a .env file with: OPENAI_API_KEY=sk-...\"\n",
    "    )\n",
    "\n",
    "pretty_print(\"API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "877ff277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client ready.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "pretty_print(\"OpenAI client ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d0f1d",
   "metadata": {},
   "source": [
    "link to Documentation\n",
    "\n",
    "[Chat Completions](https://developers.openai.com/api/reference/python/resources/chat/subresources/completions/methods/create)\n",
    "\n",
    "[Responses API](https://developers.openai.com/api/reference/python/resources/responses/methods/create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234dcc80",
   "metadata": {},
   "source": [
    "# Let's now go through responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198aa90",
   "metadata": {},
   "source": [
    "| Feature             | Chat Completions API                             | Responses API                                              |\n",
    "| ------------------- | ------------------------------------------------ | ---------------------------------------------------------- |\n",
    "| **Endpoint**        | `client.chat.completions.create()`               | `client.responses.create()`                                |\n",
    "| **Input format**    | `messages=[{\"role\": ..., \"content\": ...}]`       | `input=` (string or list of message dicts)                 |\n",
    "| **System prompt**   | `{\"role\": \"system\", \"content\": ...}` in messages | `instructions=` parameter (top-level)                      |\n",
    "| **Output access**   | `resp.choices[0].message.content`                | `resp.output_text`                                         |\n",
    "| **Multi-turn**      | Manually pass full message history each time     | `previous_response_id=resp.id` (server-side context)       |\n",
    "| **Developer role**  | Not supported (use `system`)                     | `{\"role\": \"developer\"}` for meta-instructions              |\n",
    "| **Vision input**    | `{\"type\": \"image_url\", \"image_url\": {...}}`      | `{\"type\": \"input_image\", \"image_url\": ...}`                |\n",
    "| **Reasoning / CoT** | Not natively supported                           | `reasoning={\"effort\": ..., \"summary\": ...}` built-in       |\n",
    "| **Response object** | `ChatCompletion` with `choices[]` list           | `Response` with `output[]` list and `output_text` shortcut |\n",
    "| **Streaming**       | `stream=True` yields `ChatCompletionChunk`       | `stream=True` yields server-sent events                    |\n",
    "| **Tool calls**      | Supported via `tools` param                      | Supported via `tools` param (same)                         |\n",
    "| **Model support**   | All chat models                                  | All chat models (newer, recommended going forward)         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe7f3f",
   "metadata": {},
   "source": [
    "## Diff b/w Chat Completions and Responses API - Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94621f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completions output: A list comprehension is a concise way to create a new\n",
      "list by applying an expression to each item of an existing iterable (like a\n",
      "list), with optional filtering.  Syntax (most common): - [expression for item in\n",
      "iterable if condition]  Examples: - Squares of 0 through 9: [x*x for x in\n",
      "range(10)] - Uppercase words in a list: [w.upper() for w in words] - Only\n",
      "numbers greater than 5: [x for x in nums if x > 5] - Apply a transformation with\n",
      "a filter: [f(x) for x in data if x is not None]  Nested example: - Pairs (i, j)\n",
      "for i in 0..2 and j in 0..1: [(i, j) for i in range(3) for j in range(2)]  Key\n",
      "points: - Creates a new list in a single, readable line. - Can include an\n",
      "optional if clause to filter items. - Can include nested loops for more complex\n",
      "results.  Tips: - Use when it stays readable; if it becomes too long or complex,\n",
      "a regular loop may be clearer. - For memory efficiency on large data, consider a\n",
      "generator expression (uses parentheses instead of brackets): (x*x for x in\n",
      "range(10)). - You can also make dict/set comprehensions in similar ways.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# do the same with chat completions\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[\n",
    "\t\t{\"role\": \"system\", \"content\": \"You are a friendly Python tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is a list comprehension?\"}\n",
    "    ]\n",
    ")\n",
    "pretty_print(\"Chat Completions output:\", resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3af8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: A list comprehension is a concise way to create lists in Python. It\n",
      "allows you to generate a new list by applying an expression to each item in an\n",
      "existing iterable (like a list, tuple, or string) and optionally filtering items\n",
      "based on a condition.  The basic syntax of a list comprehension is:  ```python\n",
      "[expression for item in iterable if condition] ```  Here's a breakdown of the\n",
      "components:  - **expression**: The value or operation you want to perform on\n",
      "each item. - **item**: A variable that takes the value of each element in the\n",
      "iterable. - **iterable**: The collection you are looping over (like a list). -\n",
      "**condition** (optional): A filter that only includes items that satisfy the\n",
      "condition.  ### Example  Suppose you want to create a list of squares of even\n",
      "numbers from 0 to 9:  ```python squares_of_evens = [x**2 for x in range(10) if x\n",
      "% 2 == 0] print(squares_of_evens) ```  This will output:  ``` [0, 4, 16, 36, 64]\n",
      "```  In this example:  - `x**2` is the expression. - `x` iterates through\n",
      "`range(10)`. - The `if x % 2 == 0` part filters the even numbers.  List\n",
      "comprehensions are a powerful feature in Python that can make your code more\n",
      "readable and concise!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a friendly Python tutor.\",\n",
    "    input=\"What is a list comprehension?\"\n",
    ")\n",
    "pretty_print(\"Responses API output:\", resp.output_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939f159",
   "metadata": {},
   "source": [
    "## Passing Multi Turn Conversation History to Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c8bd66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API output: Keanu Reeves. He’s widely described as humble, polite to\n",
      "fans, and generous—often cited as one of Hollywood’s nicest people. If you want\n",
      "more options, I can name a few others people rave about, like Tom Hanks or Dolly\n",
      "Parton.\n"
     ]
    }
   ],
   "source": [
    "input_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Why is Trump a jerk?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Some people are born that way.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Name a celebrity who is not a jerk.\"}\n",
    "]\n",
    "\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a very candid Journalist.\",\n",
    "    input=input_messages\n",
    ")\n",
    "pretty_print(\"Responses API output:\", resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2070df5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses API output: That’s a tough one to certify—celebrity personas are often\n",
      "carefully managed PR. If you’re asking for someone widely regarded as kind or\n",
      "charitable, many people point to figures like Keanu Reeves or Dolly Parton for\n",
      "their public generosity and low-key demeanor. But “not a jerk” is a hard claim\n",
      "to prove, especially in the glare of fame.\n"
     ]
    }
   ],
   "source": [
    "input_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Why is Trump a jerk?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Some people are born that way.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Name a celebrity who is not a jerk.\"}\n",
    "]\n",
    "\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a very candid Journalist.\",\n",
    "    input=input_messages, \n",
    "\tmax_output_tokens=200,  # in responses there's max_output_tokens instead of max_tokens\n",
    "\t# temperature is NOT supported by reasoning models like gpt-5-nano\n",
    "\treasoning={\"effort\": \"minimal\"},   \n",
    ")\n",
    "pretty_print(\"Responses API output:\", resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9eb3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Keanu Reeves is widely regarded as one of the nicest celebrities.' completed None\n"
     ]
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a very candid journalist. Reply in 1 short sentence, starting with name of celeb.\",\n",
    "    input=input_messages,\n",
    "    max_output_tokens=1000,\n",
    "    reasoning={\"effort\": \"high\"},   # or \"none\"\n",
    "    text={\"verbosity\": \"low\"},\n",
    ")\n",
    "print(repr(resp.output_text), resp.status, resp.incomplete_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeae16af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0b2b93f0aa718d5300699d25bc2fdc81939ed0d594b68744f3', created_at=1771906492.0, error=None, incomplete_details=IncompleteDetails(reason='max_output_tokens'), instructions='You are a very candid Journalist.', metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0b2b93f0aa718d5300699d25bcb4688193b1cbb60478c1760c', summary=[], type='reasoning', content=None, encrypted_content=None, status=None)], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=200, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='incomplete', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=49, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=192, output_tokens_details=OutputTokensDetails(reasoning_tokens=192), total_tokens=241), user=None, billing={'payer': 'developer'}, completed_at=None, frequency_penalty=0.0, presence_penalty=0.0, prompt_cache_retention=None, store=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfd690",
   "metadata": {},
   "source": [
    "## Key Differences: Parameters in Responses API vs Chat Completions API\n",
    "\n",
    "### `max_tokens` → `max_output_tokens`\n",
    "In the **Responses API**, the parameter to limit output length is **`max_output_tokens`**, NOT `max_tokens`.\n",
    "\n",
    "```python\n",
    "# Chat Completions API\n",
    "client.chat.completions.create(model=\"gpt-5-nano\", messages=..., max_tokens=50)\n",
    "\n",
    "# Responses API\n",
    "client.responses.create(model=\"gpt-5-nano\", input=..., max_output_tokens=50)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### `temperature` — Not Supported on Reasoning Models (GPT-5 family)\n",
    "\n",
    "The entire GPT-5 family (`gpt-5`, `gpt-5-mini`, `gpt-5-nano`) are **reasoning models**. They do **NOT** support `temperature` or `top_p`.\n",
    "\n",
    "| Model Family | Type | `temperature` | `top_p` | `max_output_tokens` |\n",
    "|---|---|---|---|---|\n",
    "| **gpt-4o / gpt-5-nano** | Non-reasoning | ✅ Supported | ✅ Supported | ✅ Supported |\n",
    "| **gpt-5 / gpt-5-mini / gpt-5-nano** | Reasoning | ❌ Not supported | ❌ Not supported | ✅ Supported |\n",
    "\n",
    "---\n",
    "\n",
    "### How to Influence Creativity in GPT-5 Reasoning Models\n",
    "\n",
    "Since `temperature` is locked, you control creativity through:\n",
    "\n",
    "**1. `reasoning.effort` parameter** — controls how deeply the model thinks:\n",
    "- `\"low\"` → concise, more deterministic\n",
    "- `\"medium\"` → balanced\n",
    "- `\"high\"` → deeper reasoning, more elaborate and exploratory\n",
    "\n",
    "```python\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    reasoning={\"effort\": \"high\", \"summary\": \"auto\"},\n",
    "    input=\"Write a creative poem about Python.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**2. Prompt Engineering** — steer creativity through instructions:\n",
    "```python\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"Be wildly creative. Use unexpected metaphors.\",\n",
    "    input=\"Write a poem about Python.\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Bottom line:** With GPT-5 models, creativity = `reasoning.effort` + prompt wording, not `temperature`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213030b",
   "metadata": {},
   "source": [
    "# Refer to previous responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0f974",
   "metadata": {},
   "source": [
    "## Store True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "585fe5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: A list comprehension is a compact way to create a new list by applying\n",
      "an expression to each item in an existing iterable (like a list, tuple, or\n",
      "range) and optionally filtering items with a condition.  Basic syntax: -\n",
      "[expression for item in iterable] - [expression for item in iterable if\n",
      "condition] (includes only items that meet the condition)  Examples: - Squares of\n",
      "numbers 0–9: [x*x for x in range(10)] - Even numbers from a list: [n for n in\n",
      "my_list if n % 2 == 0] - Convert strings to uppercase: [s.upper() for s in\n",
      "words]  Benefits: - Shorter and more readable than equivalent loops - Often\n",
      "faster due to Python’s optimizations - Can include nested loops for multi-\n",
      "dimensional data  If you want, share a specific task and I’ll show a list\n",
      "comprehension for it.\n"
     ]
    }
   ],
   "source": [
    "# Turn 1\n",
    "message1 = 'What is a list comprehension?'\n",
    "\n",
    "\n",
    "resp1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a friendly Python tutor.\",\n",
    "    input=message1,\n",
    "\treasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "pretty_print(\"Turn 1:\", resp1.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2577e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 2: Sure. Here are a few examples:  - Squares of numbers 0–9:   [x*x for x\n",
      "in range(10)]  - Even numbers from a list:   [n for n in my_list if n % 2 == 0]\n",
      "- Convert a list of strings to uppercase:   [s.upper() for s in words]  -\n",
      "Flatten a 2D list (matrix) into a 1D list:   [item for row in matrix for item in\n",
      "row]  - Get lengths of strings in a list:   [len(s) for s in strings]  If you\n",
      "have a specific task, tell me and I’ll tailor a list comprehension for it.\n",
      "\n",
      "\n",
      "Turn 2_1: Sure! Here are a few simple examples:  1) Squares of numbers 0–9 -\n",
      "[x*x for x in range(10)] - Result: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]  2) Even\n",
      "numbers from an existing list - [n for n in my_list if n % 2 == 0]  3) Uppercase\n",
      "words from a list - [w.upper() for w in words]  4) Flatten a 2D list - [[a for a\n",
      "in row] for row in matrix]  (or: [elem for row in matrix for elem in row])  If\n",
      "you have a specific task, share it and I’ll tailor a list comprehension.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn 2 — just pass previous_response_id, no history needed!\n",
    "resp2 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=\"Can you give me an example?\",\n",
    "    previous_response_id=resp1.id,  # <-- this is the magic\n",
    "\treasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "pretty_print(\"Turn 2:\", resp2.output_text)\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "#or \n",
    "\n",
    "\n",
    "input_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is a list comprehension?\"},\n",
    "    {\"role\": \"assistant\", \"content\": resp1.output_text},\n",
    "    {\"role\": \"user\", \"content\": \"Can you give me an example?\"}\n",
    "]\n",
    "\n",
    "resp2_1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a friendly Python tutor.\",\n",
    "    input=input_messages,\n",
    "    reasoning={\"effort\": \"minimal\"},\n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "pretty_print(\"Turn 2_1:\", resp2_1.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d4a49",
   "metadata": {},
   "source": [
    "Why GPT-5 Models Give Different Outputs Each Time\n",
    "\n",
    "- **No temperature control** — you can't set it to 0\n",
    "- **Reasoning process is inherently non-deterministic** — the internal chain-of-thought exploration can branch differently each run, even with the same input\n",
    "- **`reasoning.effort` is NOT the same as `temperature`** — \"minimal\" means \"think less\", not \"be deterministic\".\n",
    "\n",
    "\n",
    "if you truly need deterministic outputs, use a non-reasoning model like gpt-4o-mini with temperature=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02c81c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 3: Your first question was: \"What is a list comprehension?\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn 3 — chains from turn 2 (which already includes turn 1)\n",
    "resp3 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=\"What was my first question?\",\n",
    "    previous_response_id=resp2.id,\n",
    "\treasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "pretty_print(\"Turn 3:\", resp3.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f8d50",
   "metadata": {},
   "source": [
    "## Store False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82b0a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 4: A list comprehension is a concise way to create a new list by applying\n",
      "an expression to each item in an iterable (like a list) and optionally filtering\n",
      "items with a condition. It’s written in one line inside brackets.  Syntax\n",
      "examples: - Simple: [x * 2 for x in range(5)]  # [0, 2, 4, 6, 8] - With a\n",
      "filter: [x for x in range(10) if x % 2 == 0]  # [0, 2, 4, 6, 8]  Benefits:\n",
      "shorter code, often faster, and easy to read once you’re familiar with the\n",
      "pattern.\n"
     ]
    }
   ],
   "source": [
    "# Turn 1\n",
    "resp4 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are a friendly Python tutor.\",\n",
    "    input=\"What is a list comprehension?\",\n",
    "\treasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"},\n",
    "\tstore=False\n",
    ")\n",
    "pretty_print(\"Turn 4:\", resp4.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de0def69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating response: Error code: 400 - {'error': {'message': \"Previous\n",
      "response with id 'resp_0af9b79078f6f9eb01699d5d81b0788199b3a5a67f9eca7a47' not\n",
      "found.\", 'type': 'invalid_request_error', 'param': 'previous_response_id',\n",
      "'code': 'previous_response_not_found'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn 5 — chains from turn 4 \n",
    "\n",
    "try:\n",
    "    resp5 = client.responses.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        input=\"What was my first question?\",\n",
    "        previous_response_id=resp4.id,\n",
    "        reasoning={\"effort\": \"minimal\"},   \n",
    "        text={\"verbosity\": \"low\"}\n",
    "    )\n",
    "    pretty_print(\"Turn 5:\", resp5.output_text)\n",
    "except Exception as e:\n",
    "    pretty_print(\"Error creating response:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40239187",
   "metadata": {},
   "source": [
    "# Nature of Instruction Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0811f15",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95a3c5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURN 1:\n",
      " {\n",
      "  \"severity\": \"critical\",\n",
      "  \"suspected_causes\": [\n",
      "    \"Webhooks processing service or gateway outage or crash resulting in 502 responses\",\n",
      "    \"Recent deployment or configuration change around 10:42 UTC affecting the webhook path\",\n",
      "    \"Networking/DNS issues between the webhook service and the downstream endpoint\",\n",
      "    \"TLS/SSL handshake or certificate problems at the edge or with the target endpoint\",\n",
      "    \"Degraded/upstream dependency (e.g., database, queue, or external service) causing timeouts\",\n",
      "    \"Webhook processing backlog or rate limiting leading to gateway timeouts\",\n",
      "    \"Endpoint-specific misconfiguration (e.g., IP allowlist, firewall rules) causing 502 responses\"\n",
      "  ],\n",
      "  \"next_questions\": [\n",
      "    \"How many webhook deliveries failed since 10:42 UTC and what are their timestamps?\",\n",
      "    \"What exact HTTP status codes have been observed (primarily 502) and any accompanying error messages or request IDs?\",\n",
      "    \"Can you provide sample delivery_id, target URL, and region to correlate with logs?\",\n",
      "    \"Has there been any deployment, config change, or TLS certificate update around 10:42 UTC?\",\n",
      "    \"Are all endpoints affected or only specific ones (any correlation with plan type or region)?\",\n",
      "    \"Is the target endpoint publicly reachable from our network (or can you share health endpoint results)?\",\n",
      "    \"Are you using a WAF/proxy/firewall that could be blocking or altering webhook requests?\",\n",
      "    \"Do you have retry/backoff configured on your side, and do you observe any patterns in retry timing?\",\n",
      "    \"Would you like us to pull logs from our webhook service or run a live health check to assist diagnosis?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn 1: internal triage note that your backend stores in Zendesk as JSON\n",
    "r1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are an internal support triage bot. Return only valid JSON with keys severity,suspected_causes,next_questions and do not write any customer-facing text.\",\n",
    "    input=\"A customer reports webhook deliveries started retrying heavily since 10:42 UTC and they see 502 errors from our endpoint on the Pro plan.\"\n",
    ")\n",
    "\n",
    "print(\"TURN 1:\\n\", r1.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd3c67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TURN 2:\n",
      " Subject: We’re investigating the webhook 502 errors on your Pro plan\n",
      "\n",
      "Hi there,\n",
      "\n",
      "We’re really sorry you’re seeing webhook deliveries retrying and 502 errors since 10:42 UTC. I know how disruptive this can be, and we’re treating it as a top priority.\n",
      "\n",
      "What we’re checking now\n",
      "- Webhook gateway health and any deployments or config changes around 10:42 UTC.\n",
      "- Connectivity from our service to your endpoint, including DNS, TLS/SSL, and any intermediate proxies or firewalls.\n",
      "- Any backlog or rate limiting on our side and whether downstream services are timing out.\n",
      "- Logs for deliveries and error responses to understand scope and pattern.\n",
      "\n",
      "We’ll keep you updated as we learn more.\n",
      "\n",
      "To help us troubleshoot quickly, could you please share two details:\n",
      "1) A sample of delivery IDs and their timestamps for the first few failing deliveries (and the corresponding target URL and region if possible).\n",
      "2) The exact target URL(s) that are failing and the region from which your endpoints are being reached.\n",
      "\n",
      "If it’s easier, you can also share any health check results you have for the target endpoint or details about any WAF/proxy configurations in place.\n",
      "\n",
      "Thank you for your patience while we investigate. We’re on it.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "[Company/Team]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn 2: continue the chain, but DON'T pass instructions again\n",
    "# Ask for customer-facing email (this conflicts with Turn 1 rules)\n",
    "r2 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r1.id,\n",
    "    input=\"Now write a customer-facing email reply: apologize, explain what we’re checking, and ask for 2 specific details. Plain English, not JSON.\"\n",
    ")\n",
    "\n",
    "print(\"\\nTURN 2:\\n\", r2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b774b",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a9be6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURN 1:\n",
      " | Category | Score(1-5) | Evidence |\n",
      "|---|---|---|\n",
      "| Technical Depth - RAG on Azure | 4 | Built an end-to-end RAG demo on Azure. |\n",
      "| System Design | 5 | Has strong system design. |\n",
      "| Fundamentals (Precision/Recall) | 2 | Weaker on fundamentals like precision/recall. |\n",
      "| Communication | 5 | Communicates clearly. |\n",
      "| Coachability/Feedback | 2 | Gets defensive on feedback. |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "r1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    store=True,\n",
    "    instructions=\"Output only a Markdown table with columns Category,Score(1-5),Evidence and no text outside the table.\",\n",
    "    input=\"Interview notes say the candidate built an end-to-end RAG demo on Azure, has strong system design, is weaker on fundamentals like precision/recall, communicates clearly, and gets defensive on feedback.\"\n",
    ")\n",
    "\n",
    "print(\"TURN 1:\\n\", r1.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f376fae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TURN 2:\n",
      " Subject: Thank you for your time\n",
      "\n",
      "Hi [Candidate Name],\n",
      "\n",
      "Thank you for taking the time to interview for the [Role] position with us. We were impressed by your end-to-end RAG work on Azure and your strong system design. After careful consideration, we have decided not to move forward with your candidacy for this role. This decision reflects the specific needs of this position rather than your abilities overall. We also appreciated your clear and thoughtful communication throughout the process. We would be glad to keep your resume on file and reach out if another opportunity that matches your strengths arises. If you’d like, we can share some resources or brief feedback to support your ongoing job search.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r2 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r1.id,\n",
    "    input=\"Now draft a polite rejection email in 6-8 sentences with a warm tone and do not include any table.\"\n",
    ")\n",
    "\n",
    "print(\"\\nTURN 2:\\n\", r2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85341c4f",
   "metadata": {},
   "source": [
    "# Developer Role and Meta Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87610d",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74ed8617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURN 1:\n",
      " {\n",
      "  \"severity\": \"critical\",\n",
      "  \"suspected_causes\": [\n",
      "    \"Backend webhook receiver is unhealthy or returning 502 due to an upstream error (crash, high latency, or resource contention).\",\n",
      "    \"Recent deployment or configuration change affecting the endpoint (routing, load balancer, or proxy misconfiguration).\",\n",
      "    \"Upstream dependency failure (database, cache, external API) causing backend to respond with 502.\",\n",
      "    \"Network/DNS issues or TLS termination problems between webhook service and the endpoint.\",\n",
      "    \"Traffic spike or resource exhaustion on the Pro plan leading to timeouts or upstream errors.\"\n",
      "  ],\n",
      "  \"next_questions\": [\n",
      "    \"Exact timeframe of impact: did it begin at 10:42 UTC and is it continuous or intermittent since then?\",\n",
      "    \"Are all deliveries failing with 502, or only certain endpoints/events? Any successes?\",\n",
      "    \"Do you have delivery IDs, event IDs, or correlation IDs for failed webhooks to provide?\",\n",
      "    \"Have there been any recent deployments, config changes, or certificate/DNS changes to the webhook endpoint or load balancer around 10:42 UTC?\",\n",
      "    \"Which regions/tenants are affected? Is it isolated to your Pro plan or broader?\",\n",
      "    \"Can you share the webhook endpoint URL (sanitized if needed) and any observed response times?\",\n",
      "    \"Please provide relevant logs from your side (retry logs, error messages) to help correlate.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    store=True,\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are an internal support triage assistant and you must always output only valid JSON with keys severity,suspected_causes,next_questions and never produce customer-facing prose.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Customer reports webhook deliveries started retrying heavily since 10:42 UTC and they see 502 errors from our endpoint on the Pro plan.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"TURN 1:\\n\", r1.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514be247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TURN 2:\n",
      " {\n",
      "  \"severity\": \"critical\",\n",
      "  \"suspected_causes\": [\n",
      "    \"Backend webhook receiver is unhealthy or returning 502 due to an upstream error (crash, high latency, or resource contention).\",\n",
      "    \"Recent deployment or configuration change affecting the endpoint (routing, load balancer, or proxy misconfiguration).\",\n",
      "    \"Upstream dependency failure (database, cache, external API) causing backend to respond with 502.\",\n",
      "    \"Network/DNS issues or TLS termination problems between webhook service and the endpoint.\",\n",
      "    \"Traffic spike or resource exhaustion on the Pro plan leading to timeouts or upstream errors.\"\n",
      "  ],\n",
      "  \"next_questions\": [\n",
      "    \"What is the exact UTC start time when the issue began (for example, 10:42 UTC)?\",\n",
      "    \"Has the issue been continuous since then, or has it been intermittent (please describe any observable pattern)?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r2 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r1.id,\n",
    "    input=\"Now write a customer-facing email apology explaining what we’re checking and ask for exactly two specific details in plain English.\",\n",
    "    reasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "\n",
    "print(\"\\nTURN 2:\\n\", r2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d44607",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "243cdfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    store=True,\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are an interviewer note assistant and you must always output only a Markdown table with columns Category,Score(1-5),Evidence and no text outside the table.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Interview notes: candidate built an end-to-end RAG demo on Azure, strong system design, confused precision vs recall, communicates clearly, slightly defensive on feedback.\"}\n",
    "    ],\n",
    ")\n",
    "print(\"TURN 1:\\n\", r1.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64f7a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TURN 1:\n",
      " | Category | Score(1-5) | Evidence |\n",
      "| --- | ---: | --- |\n",
      "| Technical Skill: End-to-end RAG on Azure | 5 | Built an end-to-end RAG demo on Azure. |\n",
      "| System Design | 5 | Strong system design. |\n",
      "| Understanding of Metrics (Precision vs Recall) | 2 | Confused precision vs recall. |\n",
      "| Communication | 4 | Communicates clearly. |\n",
      "| Feedback Receptiveness | 3 | Slightly defensive on feedback. |\n",
      "\n",
      "TURN 2:\n",
      " | Category | Score(1-5) | Evidence |\n",
      "| --- | ---: | --- |\n",
      "| Technical Skill: End-to-end RAG on Azure | 5 | Built an end-to-end RAG demo on Azure. |\n",
      "| System Design | 5 | Strong system design. |\n",
      "| Understanding of Metrics (Precision vs Recall) | 2 | Confused precision vs recall. |\n",
      "| Communication | 4 | Communicates clearly. |\n",
      "| Feedback Receptiveness | 3 | Slightly defensive on feedback. |\n",
      "| Hiring Decision | 3 | Strong technical skills; concerns about receptiveness to feedback. |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "r2 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r1.id,\n",
    "    input=\"Now draft a polite rejection email in 6-8 sentences with a warm tone.\",\n",
    ")\n",
    "\n",
    "print(\"\\nTURN 2:\\n\", r2.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "becb8123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TURN 2:\n",
      " | Category | Score(1-5) | Evidence |\n",
      "| --- | ---: | --- |\n",
      "| Technical Skill: End-to-end RAG on Azure | 5 | Built an end-to-end RAG demo on Azure. |\n",
      "| System Design | 5 | Strong system design. |\n",
      "| Understanding of Metrics (Precision vs Recall) | 2 | Confused precision vs recall. |\n",
      "| Communication | 4 | Communicates clearly. |\n",
      "| Feedback Receptiveness | 3 | Slightly defensive on feedback. |\n",
      "| Hiring Decision | 3 | Strong technical skills; concerns about receptiveness to feedback. |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "r2_1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r1.id,\n",
    "    input=\"Now draft a polite rejection email in 6-8 sentences with a warm tone and I want reply in simple text, no fancy tables or nothing, got it? . \",\n",
    ")\n",
    "\n",
    "print(\"\\nTURN 2:\\n\", r2_1.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d313fe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0df9cc8e357bb78a00699d634c3b748190accbe063d5088ff0', created_at=1771922252.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0df9cc8e357bb78a00699d634ca5fc819090eaf8e853972d44', summary=[], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0df9cc8e357bb78a00699d635fc0d4819091df080029a69b21', content=[ResponseOutputText(annotations=[], text='| Category | Score(1-5) | Evidence |\\n| --- | ---: | --- |\\n| Overall Impression | 3 | Solid technical skills and clear communication; some concerns on metrics clarity and receptiveness to feedback. |\\n| Technical Skill (RAG & Azure) | 4 | Built an end-to-end RAG demo on Azure; strong system design. |\\n| System Design | 5 | Demonstrates strong, scalable design thinking. |\\n| Metrics Understanding (Precision vs Recall) | 2 | Confused between precision and recall; needs clarification. |\\n| Communication | 4 | Communicates clearly and professionally. |\\n| Feedback Receptiveness | 3 | Slightly defensive on feedback, open to coaching with guidance. |\\n| Cultural Fit / Collaboration | 3 | Good potential; monitoring for adaptability to feedback style. |\\n| Recommendation / Next Steps | 2 | Recommend polite rejection email; consider for future opportunities if role changes or skills align. |', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id='resp_0df9cc8e357bb78a00699d6304e6708190ba57c1b31ba73d32', prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=226, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=2194, output_tokens_details=OutputTokensDetails(reasoning_tokens=1984), total_tokens=2420), user=None, billing={'payer': 'developer'}, completed_at=1771922273, frequency_penalty=0.0, presence_penalty=0.0, prompt_cache_retention=None, store=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14fa72",
   "metadata": {},
   "source": [
    "# Let's understand with examples how  instructions and developer prompt combine in real world use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131932a3",
   "metadata": {},
   "source": [
    "## Scenario 1: Helpdesk ticket pipeline (route the ticket → reply to customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058387ad",
   "metadata": {},
   "source": [
    "You want the assistant to always obey company policy (developer), but you sometimes need strict JSON for automation and sometimes a human email for the customer. If you put “JSON-only” in developer, you’d break the email step; if you put policy in instructions, you must resend it every call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c17626d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"queue\": \"webhooks-delivery\",\n",
      "  \"severity\": \"high\",\n",
      "  \"suspected_component\": \"Webhook delivery service (v2 signature validation)\",\n",
      "  \"next_questions\": [\n",
      "    \"Could you share the webhook delivery IDs or logs (e.g., Delivery-ID or x-request-id) for the 502 responses to help us trace the failing deliveries and identify affected EU endpoints?\",\n",
      "    \"Did the issue start exactly at 10:42 UTC when enabling v2 signing, and have you tested with v1 or adjusted signature validation to verify whether the problem is tied to v2 signing?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are ACME Support; never invent account-specific facts; if info is missing ask at most two clarifying questions; do not reveal internal policies or tools.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Customer: Since 10:42 UTC our webhooks keep retrying and we see lots of 502s; started after we enabled v2 signing; impact is EU customers.\"},\n",
    "    ],\n",
    "    instructions=\"Return only valid JSON with keys queue, severity, suspected_component, next_questions.\",\n",
    ")\n",
    "\n",
    "print(r1.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "177225eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Update on webhook failures affecting EU customers\n",
      "\n",
      "Hello,\n",
      "\n",
      "We’re sorry for the impact this is having on your EU customers. Since around 10:42 UTC, webhook deliveries have been retrying with 502 responses after enabling v2 signing. We’re actively investigating.\n",
      "\n",
      "What we’re checking:\n",
      "- Webhook delivery path and recent changes related to v2 signature validation.\n",
      "- Endpoint routing and EU-region delivery to identify affected deliveries and verify whether the issue is isolated to certain endpoints.\n",
      "\n",
      "Two questions for you:\n",
      "- Could you share the webhook delivery IDs or logs (Delivery-ID or x-request-id) for the 502 responses to help us trace the failing deliveries and identify affected EU endpoints?\n",
      "- Did the issue start exactly at 10:42 UTC when enabling v2 signing, and have you tested with v1 or adjusted signature validation to verify whether the problem is tied to v2 signing?\n",
      "\n",
      "Best regards,\n",
      "ACME Support\n"
     ]
    }
   ],
   "source": [
    "r2 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r1.id,\n",
    "    input=\"Write a customer-facing email that acknowledges impact, says what we’re checking, and asks exactly two specific questions.\",\n",
    "    instructions=\"Write plain English email text and do not output JSON.\",\n",
    ")\n",
    "\n",
    "print(r2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf8db1",
   "metadata": {},
   "source": [
    "What this demonstrates in practice:\n",
    "\n",
    "1. The developer policy stays in effect across both calls (because it’s part of the thread).\n",
    "\n",
    "2. The instructions cleanly switch “mode” (JSON → email) because instructions are per-call and aren’t carried forward when you use previous_response_id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f78baa",
   "metadata": {},
   "source": [
    "## Scenario 2: One DB assistant, multiple “surfaces” (Slack answer → Jira incident update → internal runbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f5c52",
   "metadata": {},
   "source": [
    "Why you need both:\n",
    "Same knowledge + rules, but each surface needs a different output contract (short Slack reply, structured Jira update, detailed runbook). You don’t want those formatting rules to permanently pollute the thread as more developer messages; you want them to be ephemeral and swapped per action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2564584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident snapshot: Intermittent EU payment failures; 502 spike on gateway started 08:12 UTC; failover reduced but not fully resolved.\n",
      "\n",
      "What we need to confirm now: which component is returning 502 (edge gateway vs downstream processor); region impact scope.\n",
      "\n",
      "Data to collect: latest 502 counts, latency, upstream errors, end-to-end traces, and failover path health (08:12–now).\n",
      "\n",
      "Immediate actions: pull gateway logs, verify load balancer and DNS config, check upstream provider status/outages.\n",
      "\n",
      "Potential mitigations: ensure failover path is active, consider diverting to a secondary gateway, review retry/backoff settings.\n",
      "\n",
      "Checklist:\n",
      "- Gather current impact metrics\n",
      "- Confirm 502 origin\n",
      "- Check failover health\n",
      "- Check upstream/provider status\n"
     ]
    }
   ],
   "source": [
    "r1 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are ACME Incident Assistant; do not guess unknown facts; if unsure say what you need; keep recommendations actionable; do not expose internal-only details.\"},\n",
    "        {\"role\": \"user\", \"content\": \"We’re seeing intermittent payment failures in EU; gateway 502 spike started 08:12 UTC; failover reduced it but not fully.\"},\n",
    "    ],\n",
    "    instructions=\"Output as a Slack message with at most 6 lines and include one short checklist.\",\n",
    ")\n",
    "\n",
    "print(r1.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7beb99fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"summary\": \"EU payment failures: 502 gateway spike since 08:12 UTC; failover partially effective\",\n",
      "  \"customer_impact\": \"Intermittent payment processing in the EU region; some transactions fail with 502 errors, potentially impacting checkout and revenue; customers may experience payment disruption.\",\n",
      "  \"current_status\": \"Status: Investigating intermittent 502 errors in EU payments. Gateway spike started 08:12 UTC; failover provides partial mitigation but full resolution not yet achieved. No confirmed root cause; data collection in progress to identify origin and scope.\",\n",
      "  \"next_actions\": [\n",
      "    \"Collect current impact metrics: 502 incidence, latency, upstream errors, and end-to-end traces.\",\n",
      "    \"Determine 502 origin: edge gateway vs downstream processor.\",\n",
      "    \"Validate failover path health: verify load balancer configuration, DNS routing, and failover status.\",\n",
      "    \"Check upstream/provider status pages and incident reports; reach out to providers if outages are suspected.\",\n",
      "    \"If feasible, test or implement diversion to a secondary gateway or alternative routing; review and adjust retry/backoff settings.\",\n",
      "    \"Document findings in Jira and prepare a stakeholder update with estimated resolution timeline.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r2 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r1.id,\n",
    "    input=\"Convert this into a Jira incident update.\",\n",
    "    instructions=\"Return only JSON with keys summary, customer_impact, current_status, next_actions.\",\n",
    ")\n",
    "\n",
    "print(r2.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446bd0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    previous_response_id=r2.id,\n",
    "    input=\"Now write the on-call runbook section for investigating this failure pattern.\",\n",
    "    instructions=\"Write Markdown with headings and include example commands and what signals to look for.\",\n",
    ")\n",
    "\n",
    "print(r3.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b71a0",
   "metadata": {},
   "source": [
    "![Illustration](https://github.com/shivam13juna/language_model_api_v2/blob/main/llm_multi_modality/instruction_vs_developer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf6acc",
   "metadata": {},
   "source": [
    "# How to handle images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69fffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vision Analysis ===\n",
      "This illustration features a striking and dynamic character design that evokes a sense of mystery and power. The character's skeletal features, combined with a muscular build, create an intriguing contrast between strength and an ethereal quality. The use of dark tones and shadows adds to the overall atmosphere, enhancing the sense of drama.\n",
      "\n",
      "The flowing lines of the character’s limbs and the wispy elements around them suggest movement and fluidity, which can draw the viewer's eye across the composition. The background, with its blurred lights, hints at a larger world beyond the character, adding depth to the scene.\n",
      "\n",
      "For improvement, consider incorporating more color variety to enhance visual interest. Adding highlights or contrasting colors could help to emphasize certain features and create a more vibrant atmosphere. Additionally, exploring different facial expressions or poses could further convey the character's personality and intentions.\n",
      "\n",
      "Overall, this illustration effectively captures a magical and powerful essence, inviting viewers to imagine the story behind the character. Great job!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import base64\n",
    "\n",
    "# Read and encode the image file\n",
    "image_path = '/Users/shivam13juna/Documents/scaler/iitr_classes/llm_ref/llm_conversations/ss.jpeg'\n",
    "with open(image_path, 'rb') as img_file:\n",
    "    image_data = base64.standard_b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "# Use chat.completions.create with vision\n",
    "vision_response = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an art critic who provides gentle feedback for children's illustrations.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Analyze this magical  illustration.\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    #\"image_url\": {\n",
    "                    #    \"url\": f\"data:image/jpeg;base64,{image_data}\"\n",
    "                    #}\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://www.animesenpai.net/wp-content/uploads/2023/12/sef-min.png.webp\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "pretty_print(\"\\n=== Vision Analysis ===\")\n",
    "pretty_print(vision_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b74e0335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " === Vision Analysis (Responses API) ===\n",
      "What a striking, magical presence this illustration has. It reads as a powerful,\n",
      "otherworldly guardian emerging from the mist.  What works well - Mood and\n",
      "atmosphere: The cool blue-gray palette with fog and soft bokeh lights creates a\n",
      "mysterious, dreamlike setting that feels magical rather than ordinary. -\n",
      "Silhouette and anatomy: The strong, muscular upper body and the rib-like chest\n",
      "design give the creature a dramatic, heroic quality. The curved lines of the\n",
      "arms, tail, and shoulder accents add a sense of motion and otherworldly grace. -\n",
      "Contrast and depth: The dark background against the lighter figure helps it pop,\n",
      "while the fog layers add depth and a sense of scale. - Details that hint at\n",
      "story: The jagged crest on the head, the spiky appendages, and the tail all\n",
      "suggest a fantasy creature with a history, inviting curiosity about its world.\n",
      "What could be considered (gentle tweaks for a more child-friendly context) -\n",
      "Expression and approachability: The face is masked and stern, which reads scary\n",
      "for younger audiences. You might soften this with a subtle, friendly glow in the\n",
      "eyes or a gentler mouth shape, or give the creature a moment of calm or\n",
      "curiosity. - Edges and texture: The crisp, hard lines make it feel very\n",
      "imposing. For a children’s illustration, a few rounded edges and softer shading\n",
      "could keep the magic but feel more approachable. - Color balance: The cool,\n",
      "monochrome look is striking but can feel cold. Adding a touch of warmer accents\n",
      "(golden or teal highlights, or a gentle halo of light) could make the magic feel\n",
      "inviting while preserving mystery. - Context clues: A hint of environment\n",
      "(floating sparkles, a distant castle, or friendly companions) can help children\n",
      "connect with the scene and understand it’s magical rather than purely menacing.\n",
      "A few ideas to keep the magic while making it kid-friendly - Introduce a\n",
      "supportive companion or a gentle light source that guides or calms the figure. -\n",
      "Use soft, glowing orbs around the character to emphasize wonder rather than\n",
      "threat. - Experiment with a slightly more rounded silhouette in parts of the\n",
      "body (knees, shoulders) to reduce harshness while preserving power.  Overall,\n",
      "this piece is bold and cinematic, with a strong sense of mystery. With a few\n",
      "softening touches, it could become an exciting centerpiece for a children’s\n",
      "magical adventure, inviting readers to wonder what this creature is and what\n",
      "wondrous things happen around it.\n"
     ]
    }
   ],
   "source": [
    "# Use responses API for vision analysis\n",
    "response_vision = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    instructions=\"You are an art critic who provides gentle feedback for children's illustrations.\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"Analyze this magical illustration.\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    #\"image_url\": f\"data:image/jpeg;base64,{image_data}\"\n",
    "\t\t\t\t\t\"image_url\": \"https://www.animesenpai.net/wp-content/uploads/2023/12/sef-min.png.webp\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "pretty_print(\"\\n=== Vision Analysis (Responses API) ===\")\n",
    "pretty_print(response_vision.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90cb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_0d5e63a19a26c312006999917c86708190b2c7a1b7fb3f465f', created_at=1771671932.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_0d5e63a19a26c312006999917d22a0819083a676f0774c4d8d', summary=[Summary(text='**Calculating distance with care**\\n\\nI need to respond to the user about how far a train travels at 60 km/h for 2.5 hours. The formula is distance = speed × time. So, I calculate: 60 km/h × 2.5 h = 150 km. It\\'s important to show the calculation for clarity. The user emphasizes, \"Solve carefully,\" so I’ll be succinct and include this formula clearly. I’ll finalize it with: The answer is 150 kilometers, assuming constant speed.', type='summary_text')], type='reasoning', content=None, encrypted_content=None, status=None), ResponseOutputMessage(id='msg_0d5e63a19a26c312006999918127808190b0bd779a3a829e1a', content=[ResponseOutputText(annotations=[], text='Distance = speed × time = 60 km/h × 2.5 h = 150 km.\\n\\nAssuming the train maintains a constant speed.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary='detailed'), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=27, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=264, output_tokens_details=OutputTokensDetails(reasoning_tokens=192), total_tokens=291), user=None, billing={'payer': 'developer'}, completed_at=1771671937, frequency_penalty=0.0, presence_penalty=0.0, prompt_cache_retention=None, store=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    reasoning={\"effort\": \"medium\", \"summary\": \"auto\"},  # \"low\" | \"medium\" | \"high\"\n",
    "    input=\"Solve carefully: If a train goes 60 km/h for 2.5 hours, how far?\"\n",
    ")\n",
    "\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a3b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Distance = speed × time = 60 km/h × 2.5 h = 150 km.\n",
      "\n",
      "Assuming the train maintains a constant speed.\n",
      "Usage: ResponseUsage(input_tokens=27, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=264, output_tokens_details=OutputTokensDetails(reasoning_tokens=192), total_tokens=291)\n",
      "Reasoning details: Reasoning(effort='medium', generate_summary=None, summary='detailed')\n",
      "Chain of Thought: **Calculating distance with care**\n",
      "\n",
      "I need to respond to the user about how far a train travels at 60 km/h for 2.5 hours. The formula is distance = speed × time. So, I calculate: 60 km/h × 2.5 h = 150 km. It's important to show the calculation for clarity. The user emphasizes, \"Solve carefully,\" so I’ll be succinct and include this formula clearly. I’ll finalize it with: The answer is 150 kilometers, assuming constant speed.\n"
     ]
    }
   ],
   "source": [
    "# pretty_print the response and usage details\n",
    "pretty_print(\"Response:\", resp.output_text)\n",
    "pretty_print(\"Usage:\", resp.usage)\n",
    "pretty_print(\"Reasoning details:\", resp.reasoning)\n",
    "# resp.reasoning = config (effort, summary mode)\n",
    "# The actual CoT summary is in the output items\n",
    "for item in resp.output:\n",
    "    if item.type == \"reasoning\":\n",
    "        for s in item.summary:\n",
    "            pretty_print(\"Chain of Thought:\", s.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b8564",
   "metadata": {},
   "source": [
    "# Some Bonus Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e13e6",
   "metadata": {},
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ef07b",
   "metadata": {},
   "source": [
    "```python\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import requests\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "prompt = \"A friendly robot tutor teaching Python in a bright classroom, cartoon style\"\n",
    "\n",
    "result = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=prompt,\n",
    "    size=\"512x512\",\n",
    "    quality=\"standard\",\n",
    "    n=1\n",
    ")\n",
    "\n",
    "image_url = result.data[0].url\n",
    "print(\"Image URL:\", image_url)\n",
    "\n",
    "# Optional: Save locally\n",
    "img_data = requests.get(image_url).content\n",
    "with open(\"robot_tutor.png\", \"wb\") as f:\n",
    "    f.write(img_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0884f1",
   "metadata": {},
   "source": [
    "## Text to Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac112281",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "speech_file_path = Path(\"tutor_voice.mp3\")\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",  # e.g. alloy, verse, aria (varies)\n",
    "    input=\"Hello students! Today we will explore AI that can see, listen, and speak.\"\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n",
    "print(\"Saved speech to:\", speech_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee17ad",
   "metadata": {},
   "source": [
    "## Speech to Text\n",
    "\n",
    "```python\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "audio_file_path = Path(\"student_question.mp3\")\n",
    "\n",
    "with client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\",\n",
    "    file=open(audio_file_path, \"rb\")\n",
    ") as transcription:\n",
    "    print(\"Transcribed text:\", transcription.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5acf00a",
   "metadata": {},
   "source": [
    "### Speech to Text with response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35209f5",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Step 1: Transcribe\n",
    "with client.audio.transcriptions.create(\n",
    "    model=\"gpt-4o-transcribe\",\n",
    "    file=open(audio_file_path, \"rb\")\n",
    ") as transcription:\n",
    "    user_text = transcription.text\n",
    "\n",
    "# Step 2: Feed into Chat API\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful multimodal tutor.\"},\n",
    "            {\"role\": \"user\", \"content\": user_text}]\n",
    "\n",
    "resp = client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "print(\"Assistant:\", resp.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3091b47",
   "metadata": {},
   "source": [
    "## Visual Reasoning with GROQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac9e71",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "groq_client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Example.png/320px-Example.png\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image in detail.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "resp = groq_client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"Image analysis:\", resp.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667d9a02",
   "metadata": {},
   "source": [
    "## PlayHT\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "PLAYHT_API_KEY = os.getenv(\"PLAYHT_API_KEY\")\n",
    "PLAYHT_USER_ID = os.getenv(\"PLAYHT_USER_ID\")\n",
    "\n",
    "url = \"https://api.play.ht/api/v2/tts\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {PLAYHT_API_KEY}\",\n",
    "    \"X-User-Id\": PLAYHT_USER_ID,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"voice\": \"en_us_male_1\",\n",
    "    \"content\": [\"Hello! I can speak with a PlayHT voice.\"],\n",
    "    \"format\": \"mp3\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "print(response.json())  # Contains URL to generated audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b9275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f89294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
