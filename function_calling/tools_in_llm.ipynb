{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0d03cb",
   "metadata": {},
   "source": [
    "\n",
    "â€œAgenticâ€ usually implies more than â€œgood at toolsâ€:\n",
    "\n",
    "* **Goal-directed behavior over multiple steps**: it can decompose a task, execute steps, and keep going until a stopping condition is met (not just one tool call).\n",
    "* **Planning + state/memory**: it tracks intermediate results, constraints, and whatâ€™s already been tried (often with an external state store, not just the LM).\n",
    "* **Self-monitoring / control loop**: it can evaluate outcomes, detect failures, retry with a different approach, and decide when to ask for help.\n",
    "* **Autonomy level**: it can initiate actions based on goals and context (within boundaries), rather than only responding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604c394",
   "metadata": {},
   "source": [
    "# Some Prompts you can play around with?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21617879",
   "metadata": {},
   "source": [
    "Now on, Iâ€™m giving you these are some functions add(a, b) sub(a, b), mul(a, b) and div(a, b). \n",
    "\n",
    "NOTE: if you've to add more than 2 numbers, just call functions with more than 2 arguments, e.g. if you've 4 numbers, \"1, 2, 3, 4\" then you can use add(1, 2, 3, 4), likewise for multiplication, etc.\n",
    "\n",
    "If you ever need to compute any computation involging arithmetic,  just return expresssion made from these functions, donâ€™t try to compute numbers yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f0aa9",
   "metadata": {},
   "source": [
    "Shivam has 3 apples, raji has 2 oranges, 2 apples, and shikhar has 10 bananas.   Whatâ€™s total no of fruits they all have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0211b98",
   "metadata": {},
   "source": [
    "# Basics of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "688ff543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 7 and 12 together...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_something(a, b):\n",
    "    print(f\"Adding {a} and {b} together...\")\n",
    "    return a + b\n",
    "\n",
    "\n",
    "add_something(**{\"a\": 7, \"b\": 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab1fc18",
   "metadata": {},
   "source": [
    "Did you know? In Python, `**` in a function call means **â€œtake this mapping (usually a dict) and expand it into keyword arguments.â€**\n",
    "\n",
    "### Whatâ€™s happening in your call\n",
    "\n",
    "```python\n",
    "add_something(**{\"a\": 7, \"b\": 12})\n",
    "```\n",
    "\n",
    "Python sees a dict with keys `\"a\"` and `\"b\"`, and expands it as if you had written:\n",
    "\n",
    "```python\n",
    "add_something(a=7, b=12)\n",
    "```\n",
    "\n",
    "So itâ€™s not passing the dict as a single argument. Itâ€™s **unpacking** it into named parameters.\n",
    "\n",
    "### Why it works\n",
    "\n",
    "Because your function is defined with parameter names `a` and `b`:\n",
    "\n",
    "```python\n",
    "def add_something(a, b):\n",
    "```\n",
    "\n",
    "â€¦and the dict has matching keys:\n",
    "\n",
    "```python\n",
    "{\"a\": 7, \"b\": 12}\n",
    "```\n",
    "\n",
    "So `a` gets `7`, `b` gets `12`.\n",
    "\n",
    "### Rules (the important bits)\n",
    "\n",
    "1. **Keys must be strings** (valid keyword names, effectively):\n",
    "\n",
    "   ```python\n",
    "   add_something(**{1: 7, 2: 12})  # TypeError\n",
    "   ```\n",
    "\n",
    "2. **Keys must match parameter names**, unless the function accepts arbitrary keywords:\n",
    "\n",
    "   ```python\n",
    "   add_something(**{\"x\": 7, \"b\": 12})\n",
    "   # TypeError: got an unexpected keyword argument 'x'\n",
    "   ```\n",
    "\n",
    "3. You can mix normal args + `**` (but donâ€™t give the same value twice):\n",
    "\n",
    "   ```python\n",
    "   add_something(7, **{\"b\": 12})      # ok -> a=7, b=12\n",
    "   add_something(a=7, **{\"a\": 9})     # TypeError: multiple values for 'a'\n",
    "   ```\n",
    "\n",
    "4. You can also merge multiple `**` expansions:\n",
    "\n",
    "   ```python\n",
    "   add_something(**{\"a\": 7}, **{\"b\": 12})\n",
    "   ```\n",
    "\n",
    "### Related: `*` vs `**`\n",
    "\n",
    "* `*` unpacks a sequence into **positional arguments**:\n",
    "\n",
    "  ```python\n",
    "  add_something(*[7, 12])   # same as add_something(7, 12)\n",
    "  ```\n",
    "\n",
    "* `**` unpacks a mapping into **keyword arguments**:\n",
    "\n",
    "  ```python\n",
    "  add_something(**{\"a\": 7, \"b\": 12})  # same as add_something(a=7, b=12)\n",
    "  ```\n",
    "\n",
    "If you want, I can show how this interacts with `def f(*args, **kwargs)` which is where `**` really becomes obvious.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67124187",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 Â· Why Do We Need Function Calling?\n",
    "\n",
    "LLMs are impressive â€” they can write essays, explain quantum physics, draft emails. But they have some hard limits:\n",
    "\n",
    "- ðŸ§Š **Frozen in time** â€” they don't know what happened after their training cutoff\n",
    "- ðŸ”¢ **Bad at precise computation** â€” they *predict* math answers rather than *computing* them\n",
    "- ðŸš« **Can't take actions** â€” they can't send emails, query databases, or call APIs\n",
    "\n",
    "Let's actually *see* these failures before we fix them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8afc3e0",
   "metadata": {},
   "source": [
    "### 1.2 Load Your API Key Securely\n",
    "\n",
    "We **never** hardcode API keys. Instead we keep them in a `.env` file and load them at runtime with `python-dotenv`. Treat your key like a password â€” if it leaks, anyone can run up charges on your account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c6a1ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import textwrap\n",
    "\n",
    "\n",
    "\n",
    "def pretty_print(*args):\n",
    "    text = \" \".join(str(arg) for arg in args)\n",
    "    try:\n",
    "        print(textwrap.fill(text, width=80))\n",
    "    except Exception as e:\n",
    "        print(text)  # fallback to normal print if text is not a string\n",
    "\n",
    "        \n",
    "\n",
    "load_dotenv('/Users/shivam13juna/Documents/scaler/iitr_classes/llm_ref/openai_key.env')  # reads .env file in the current directory\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY not found! \"\n",
    "        \"Make sure you have a .env file with: OPENAI_API_KEY=sk-...\"\n",
    "    )\n",
    "\n",
    "pretty_print(\"API key loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e7768a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab\n"
     ]
    }
   ],
   "source": [
    "pretty_print(\"a\" + \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "29f8d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import truststore\n",
    "truststore.inject_into_ssl()\n",
    "\n",
    "#This is optional. I use VPN in my computer. Why I have to use this\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113c465",
   "metadata": {},
   "source": [
    "### 1.3 Initialize the OpenAI Client\n",
    "\n",
    "The `OpenAI` class is our gateway to every model endpoint. We create it once and reuse it throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cef8f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client ready.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "pretty_print(\"OpenAI client ready.\")\n",
    "\n",
    "MODEL  = \"gpt-5-nano\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10642544",
   "metadata": {},
   "source": [
    "### ðŸ§ª Experiment 1: Ask about real-time information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df7d26ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I donâ€™t have real-time weather access. You can check the current temperature for Bengaluru on a weather service (e.g., Weather.com, AccuWeather, or your deviceâ€™s weather app) for the exact value. If you share a location or time, I can help interpret forecast data.\n"
     ]
    }
   ],
   "source": [
    "# The model has NO access to live data â€” what does it do?\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"What is the weather in bengaluru right now? Give me the exact temperature.\",\n",
    "    reasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebfd385",
   "metadata": {},
   "source": [
    "â˜ï¸ The model either **admits it can't check**, or worse â€” **makes up a plausible-sounding answer**. Either way, it's not helpful for a user who needs real weather data.\n",
    "\n",
    "### ðŸ§ª Experiment 2: Ask for precise math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8991997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model says: 103,700.00\n",
      "Actual answer: 103506.13513513513\n"
     ]
    }
   ],
   "source": [
    "# The model PREDICTS math â€” it doesn't COMPUTE it\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"What is 1247 * 83 + 19 / 3.7? Give me answer in one line (max 10 words), the exact number, upto 2 decimal places.\",\n",
    "    reasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "print(\"Model says:\", response.output_text)\n",
    "\n",
    "# What Python actually computes\n",
    "import math\n",
    "actual = 1247 * 83 + 19 / 3.7\n",
    "print(f\"Actual answer: {actual}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a589cc3",
   "metadata": {},
   "source": [
    "Sometimes the model gets it right, sometimes it's off. The point is â€” it's **guessing**, not computing. For a banking app or scientific tool, \"usually right\" isn't good enough.\n",
    "\n",
    "### ðŸ§ª Experiment 3: Ask it to take an action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f235ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can draft the email for you. Hereâ€™s a plain text version you can send:\n",
      "\n",
      "To: john@example.com\n",
      "Subject: Meeting time updated\n",
      "Body:\n",
      "Hi John,\n",
      "\n",
      "Meeting moved to 3pm.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "\n",
      "If youâ€™d like, tell me your name and I can tailor it or format for your email client.\n"
     ]
    }
   ],
   "source": [
    "# Can the model actually DO something in the real world?\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"Send an email to john@example.com saying 'Meeting moved to 3pm'.\",\n",
    "    reasoning={\"effort\": \"minimal\"},   \n",
    "    text={\"verbosity\": \"low\"}\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555eb6c",
   "metadata": {},
   "source": [
    "The model can *write* the email â€” but it can't *send* it. It has no access to your email server, your contacts, or anything outside its text-generation bubble.\n",
    "\n",
    "---\n",
    "\n",
    "### So what do we actually want?\n",
    "\n",
    "We want the model to be able to say:\n",
    "\n",
    "> *\"I can't compute this myself, but I know there's a calculator function available. Let me ask for `compute_math(expression='1247 * 83 + 19 / 3.7')` and use the result.\"*\n",
    "\n",
    "> *\"I can't check live weather, but I know there's a `get_weather` function. Let me call `get_weather(location='Tel Aviv')` and report back.\"*\n",
    "\n",
    "**That's function calling.** The model doesn't gain superpowers â€” instead, it learns to **ask for help** from functions *you* provide.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d47b0e8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.1 Â· The Key Vocabulary\n",
    "\n",
    "Three terms you'll see everywhere. Let's nail them down with a concrete example â€” getting today's weather.\n",
    "\n",
    "### ðŸ”§ Tool (or Function)\n",
    "A piece of functionality **you** write and **describe** to the model. The model never sees your code â€” it only sees a name, a description, and a schema of what arguments the function accepts.\n",
    "\n",
    "```\n",
    "Tool name:        get_weather\n",
    "Description:      \"Get the current temperature for a city\"\n",
    "Expected input:   { \"location\": \"Tel Aviv\" }\n",
    "```\n",
    "\n",
    "### ðŸ“ž Tool Call (or Function Call)  \n",
    "When the model decides it needs a tool, it doesn't answer with text. Instead it returns a **structured request**: *\"Please call this function with these arguments.\"*\n",
    "\n",
    "```\n",
    "Model's response:  function_call â†’ get_weather(location=\"Tel Aviv\")\n",
    "                   (NOT \"The weather in Tel Aviv is 28Â°C\")\n",
    "```\n",
    "\n",
    "### ðŸ“¦ Tool Call Output (or Function Call Output)\n",
    "**Your code** actually runs the function, gets a result, and sends it back. The model then uses that real data to compose its final answer.\n",
    "\n",
    "```\n",
    "Your code runs:    get_weather(\"Tel Aviv\") â†’ {\"temp\": 28, \"unit\": \"C\"}\n",
    "You send back:     function_call_output with that result\n",
    "Model finally:     \"The current temperature in Tel Aviv is 28Â°C.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f77c631",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Â· See It Happen â€” The Model Outputs a Function Call, Not Text\n",
    "\n",
    "Let's give the model a simple `add` function and ask it to add two numbers. Watch what comes back â€” it's **not** a text answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "05640665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output items from the model:\n",
      "----------------------------------------\n",
      "  Type: reasoning\n",
      "  Type: function_call\n",
      "  Function name: add\n",
      "  Arguments: {\"a\":7,\"b\":12}\n",
      "  Call ID: call_DeRCb62JAFlxtyq8U0jbtSVx\n",
      " Response:\n"
     ]
    }
   ],
   "source": [
    "# Define a simple \"add\" tool â€” we'll explain the structure in detail next\n",
    "add_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add\",\n",
    "    \"description\": \"Add two numbers together and return the sum.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "\n",
    "# Ask the model to add â€” but give it the tool\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    instructions=\"Use the add tool for any math. Never compute math yourself.\",\n",
    "    input=\"What is 7 + 12?\",\n",
    "    tools=[add_tool],\n",
    ")\n",
    "\n",
    "# Let's inspect what came back\n",
    "print(\"Output items from the model:\")\n",
    "print(\"-\" * 40)\n",
    "for item in response.output:\n",
    "    print(f\"  Type: {item.type}\")\n",
    "    if item.type == \"function_call\":\n",
    "        print(f\"  Function name: {item.name}\")\n",
    "        print(f\"  Arguments: {item.arguments}\")\n",
    "        print(f\"  Call ID: {item.call_id}\")\n",
    "pretty_print(\" Response: \" + response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd79ecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output items from the model:\n",
      "----------------------------------------\n",
      "  Type: reasoning\n",
      "  Type: message\n",
      " Response: Earth isnâ€™t perfectly round, but it is round in the sense that\n",
      "gravity pulls all its mass toward the center, making the overall shape as close\n",
      "to a sphere as possible.  - Why a sphere? For a non-rotating chunk of matter,\n",
      "gravity tends to smooth itself into a sphereâ€”the shape with the smallest surface\n",
      "area for a given volume. - Why not a perfect sphere? Earth rotates. The spin\n",
      "creates centrifugal force that pushes material outward at the equator, producing\n",
      "a bulge. The result is an oblate spheroid (a sphere thatâ€™s slightly flattened at\n",
      "the poles). - How big is the bulge? The equatorial radius is about 6,378 km, the\n",
      "polar radius about 6,357 kmâ€”so the difference is small, but real. - What about\n",
      "mountains and oceans? They make local bumps, but they donâ€™t change the overall\n",
      "rounded shape much. The true â€œmeanâ€ shape is described by the geoid, which is an\n",
      "irregular, slightly wavy surface in terms of gravity and sea level.  In short:\n",
      "gravity makes Earth round, and rotation makes it a bit squashed at the poles. If\n",
      "you want more detail on geodesy or measurements, I can go into that.\n"
     ]
    }
   ],
   "source": [
    "# Ask the model to add â€” but give it the tool\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    instructions=\"Use the add tool for any math. Never compute math yourself.\",\n",
    "    input=\"Why is Earth round?\",\n",
    "    tools=[add_tool],\n",
    ")\n",
    "\n",
    "\n",
    "# Let's inspect what came back\n",
    "print(\"Output items from the model:\")\n",
    "print(\"-\" * 40)\n",
    "for item in response.output:\n",
    "    print(f\"  Type: {item.type}\")\n",
    "    if item.type == \"function_call\":\n",
    "        print(f\"  Function name: {item.name}\")\n",
    "        print(f\"  Arguments: {item.arguments}\")\n",
    "        print(f\"  Call ID: {item.call_id}\")\n",
    "pretty_print(\" Response: \" + response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad527740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output items from the model:\n",
      "----------------------------------------\n",
      "  Type: reasoning\n",
      "  Type: function_call\n",
      "  Function name: multiply\n",
      "  Arguments: {\"a\":1247,\"b\":83}\n",
      "  Call ID: call_zDpxNvVXzscGt6IG27J1wUsH\n",
      "  Type: function_call\n",
      "  Function name: divide\n",
      "  Arguments: {\"a\":19,\"b\":3.7}\n",
      "  Call ID: call_5n1T83Td1NATlVPKXVXl6gcq\n",
      " Response:\n"
     ]
    }
   ],
   "source": [
    "# Adding more tools doesn't change the model's behavior if the question doesn't require them\n",
    "\n",
    "add_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add\",\n",
    "    \"description\": \"Add two numbers together and return the sum.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "sub_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"subtract\",\n",
    "    \"description\": \"Subtract two numbers and return the difference.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "mul_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"multiply\",\n",
    "    \"description\": \"Multiply two numbers together and return the product.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "\n",
    "div_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"divide\",\n",
    "    \"description\": \"Divide two numbers and return the answer.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"Numerator (dividend)\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Denominator (divisor)\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract(a, b):\n",
    "    return a - b\n",
    "\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        return \"Error: Division by zero\"\n",
    "    return a / b\n",
    "\n",
    "# Ask the model to add â€” but give it the tool\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    instructions=\"Use the tools for any math. Never compute math yourself.\",\n",
    "    input=\"What is 1247 * 83 + 19 / 3.7?\",\n",
    "    tools=[add_tool, sub_tool, mul_tool, div_tool],\n",
    "    reasoning={\"effort\": \"minimal\"}\n",
    ")\n",
    "\n",
    "\n",
    "# Let's inspect what came back\n",
    "print(\"Output items from the model:\")\n",
    "print(\"-\" * 40)\n",
    "for item in response.output:\n",
    "    print(f\"  Type: {item.type}\")\n",
    "    if item.type == \"function_call\":\n",
    "        print(f\"  Function name: {item.name}\")\n",
    "        print(f\"  Arguments: {item.arguments}\")\n",
    "        print(f\"  Call ID: {item.call_id}\")\n",
    "pretty_print(\" Response: \" + response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ca3d4",
   "metadata": {},
   "source": [
    "ðŸŽ¯ **Look at that!** The model did NOT respond with \"19\". Instead it returned:\n",
    "\n",
    "- `type: \"function_call\"` â€” it's requesting a tool call\n",
    "- `name: \"add\"` â€” it picked our function\n",
    "- `arguments: {\"a\": 7, \"b\": 12}` â€” it figured out the right arguments from the user's question\n",
    "\n",
    "The model **proposed** a function call. It's now waiting for us to **execute** it and give back the result.\n",
    "\n",
    "Let's try another one â€” a weather function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b7ff71b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output items from the model:\n",
      "----------------------------------------\n",
      "  Type: reasoning\n",
      "  Type: function_call\n",
      "  Function name: get_weather\n",
      "  Arguments: {\"location\":\"Paris\"}\n",
      "  Call ID: call_lrkyH4yEt9AWVmiY7c5KTMly\n",
      " Response:\n"
     ]
    }
   ],
   "source": [
    "# Define a get_weather tool\n",
    "weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get the current temperature for a given city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City name, e.g. 'Tel Aviv', 'London'\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "# Same question as before â€” but now the model has a tool!\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"What's the weather in Paris right now?\",\n",
    "    tools=[weather_tool],\n",
    ")\n",
    "\n",
    "# Let's inspect what came back\n",
    "print(\"Output items from the model:\")\n",
    "print(\"-\" * 40)\n",
    "for item in response.output:\n",
    "    print(f\"  Type: {item.type}\")\n",
    "    if item.type == \"function_call\":\n",
    "        print(f\"  Function name: {item.name}\")\n",
    "        print(f\"  Arguments: {item.arguments}\")\n",
    "        print(f\"  Call ID: {item.call_id}\")\n",
    "pretty_print(\" Response: \" + response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684770a2",
   "metadata": {},
   "source": [
    "Without the tool, the model would have guessed or refused. **With** the tool, it says *\"call `get_weather` with `location='Paris'`\"* â€” and waits for real data.\n",
    "\n",
    "This is the fundamental shift: **the model stops pretending to know things and starts asking for help.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd562259",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Â· Anatomy of a Tool Definition\n",
    "\n",
    "Let's break down exactly what we just wrote. Every tool definition has these parts:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"type\": \"function\",          # Always \"function\" for custom tools\n",
    "    \"name\": \"add\",               # What the model calls it by\n",
    "    \"description\": \"Add two numbers together.\",   # Helps the model decide WHEN to use it\n",
    "    \"parameters\": {              # JSON Schema describing the arguments\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],           # Which fields are mandatory\n",
    "        \"additionalProperties\": False,    # No extra fields allowed (needed for strict)\n",
    "    },\n",
    "    \"strict\": True,              # Guarantee arguments match schema exactly\n",
    "}\n",
    "```\n",
    "\n",
    "**Think of it like a contract:**  \n",
    "- The `description` tells the model *\"here's what this tool does â€” use it when relevant\"*\n",
    "- The `parameters` schema tells the model *\"here's exactly what arguments to generate\"*\n",
    "- `strict: True` tells the API *\"enforce this schema â€” reject anything that doesn't match\"*\n",
    "\n",
    "> The model never sees your Python function code. It only sees this definition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30e2b4",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4 Â· The Complete Flow â€” End to End\n",
    "\n",
    "Now let's put all five steps together with our simple `add` function. This is the pattern you'll use for everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc63bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â• Step 2: Model returns a function_call (not text!) â•â•â•\n",
      "  reasoning: None\n",
      "  function_call: add({\"a\":7,\"b\":12})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Step 0: Our actual Python function (the model never sees this!)\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Step 1: Call the API with tools defined\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    instructions=\"Always use the add tool for math. Never compute yourself.\",\n",
    "    input=\"What is 7 + 12?\",\n",
    "    tools=[add_tool],       # from earlier\n",
    ")\n",
    "\n",
    "print(\"â•â•â• Step 2: Model returns a function_call (not text!) â•â•â•\")\n",
    "for item in response.output:\n",
    "    print(f\"  {item.type}: \", end=\"\")\n",
    "    if item.type == \"function_call\":\n",
    "        print(f\"{item.name}({item.arguments})\")\n",
    "    else:\n",
    "        print(getattr(item, 'content', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6215ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â• Step 3: We ran add({'a': 7, 'b': 12}) â†’ 19 â•â•â•\n"
     ]
    }
   ],
   "source": [
    "# Step 3: We execute the function with the model's arguments\n",
    "function_call = [item for item in response.output if item.type == \"function_call\"][0]\n",
    "args = json.loads(function_call.arguments)\n",
    "\n",
    "result = add(**args)       # add(a=7, b=12) â†’ 19\n",
    "print(f\"â•â•â• Step 3: We ran add({args}) â†’ {result} â•â•â•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ce40423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â• Step 5: Final answer â•â•â•\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Send the result back to the model\n",
    "# We need to include:\n",
    "#   - The model's original output (preserves its chain of thought)\n",
    "#   - Our function_call_output (the actual result, linked by call_id)\n",
    "\n",
    "#followup_input = list(response.output)     # the model's original items\n",
    "followup_input = []\n",
    "followup_input.append({\n",
    "    \"type\": \"function_call_output\",        # this is OUR result going back\n",
    "    \"call_id\": function_call.call_id,      # links to the specific function_call\n",
    "    \"output\": str(result),                 # must be a string\n",
    "})\n",
    "\n",
    "# Step 5: Model writes the final answer using the real result\n",
    "final = client.responses.create(\n",
    "    model=MODEL,\n",
    "    instructions=\"Always use the add tool for math. Never compute yourself.\",\n",
    "\tprevious_response_id=response.id,   # links to the previous response\n",
    "    input=followup_input,\n",
    "    tools=[add_tool],\n",
    ")\n",
    "\n",
    "print(f\"â•â•â• Step 5: Final answer â•â•â•\")\n",
    "print(final.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff285fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_0ef7ba8b393cd93e0069a025ac55cc819888459701fb5271fa', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseFunctionToolCall(arguments='{\"a\":7,\"b\":12}', call_id='call_NKKfTWChw4XGnOQnUm4K6unr', name='add', type='function_call', id='fc_0ef7ba8b393cd93e0069a025ae2a108198b9ec7e9d531489f5', status='completed'),\n",
       " {'type': 'function_call_output',\n",
       "  'call_id': 'call_NKKfTWChw4XGnOQnUm4K6unr',\n",
       "  'output': '19'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followup_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c88d7",
   "metadata": {},
   "source": [
    "### Let's see the same flow for `get_weather`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our fake weather function (in production, this would call a real API)\n",
    "def get_weather(location):\n",
    "    fake_data = {\"Tel Aviv\": \"28Â°C, sunny\", \"Paris\": \"18Â°C, cloudy\", \"London\": \"14Â°C, rain\"}\n",
    "    return fake_data.get(location, f\"No data for {location}\")\n",
    "\n",
    "# Step 1: Ask with the weather tool\n",
    "response = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=\"What's the weather like in Tel Aviv and London?\",\n",
    "    tools=[weather_tool],\n",
    ")\n",
    "\n",
    "# Step 2 & 3: Find all function calls, execute each\n",
    "print(\"Model requested these calls:\")\n",
    "new_input = list(response.output)\n",
    "\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\":\n",
    "        args = json.loads(item.arguments)\n",
    "        result = get_weather(**args)\n",
    "        print(f\"  â†’ {item.name}({args}) = {result}\")\n",
    "        \n",
    "        # Step 4: Append our result\n",
    "        new_input.append({\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": item.call_id,\n",
    "            \"output\": result,\n",
    "        })\n",
    "\n",
    "# Step 5: Model composes final answer with real data\n",
    "final = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=new_input,\n",
    "    tools=[weather_tool],\n",
    ")\n",
    "print(f\"\\nFinal answer:\\n{final.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ab0f6",
   "metadata": {},
   "source": [
    "### ðŸ§  What just happened â€” step by step\n",
    "\n",
    "```\n",
    "1. You  â”€â”€â–¶  API      \"What's the weather?\" + tool definitions\n",
    "2.           API â”€â”€â–¶   Model returns function_call items (not text!)\n",
    "3. You execute the function(s) with the model's arguments\n",
    "4. You  â”€â”€â–¶  API      Send back function_call_output for each call\n",
    "5.           API â”€â”€â–¶   Model writes a final answer using real data\n",
    "```\n",
    "\n",
    "The model **proposes**. Your app **executes**. The model **summarizes**.\n",
    "\n",
    "That's it â€” that's the entire pattern. Everything from here builds on exactly this loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88ba52e",
   "metadata": {},
   "source": [
    "### Same flow but with more tools and more calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aee8b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "START: User question\n",
      "   What is 1247 * 83 + 19 / 3.7?\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ROUND 1: Model response items\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "[0] type = reasoning\n",
      "[1] type = function_call\n",
      "    name     = multiply\n",
      "    call_id  = call_59EkQjUlhuBV4MPWbYSSNzvL\n",
      "    arguments(raw JSON string) = {\"a\":1247,\"b\":83}\n",
      "[2] type = function_call\n",
      "    name     = divide\n",
      "    call_id  = call_8MMWUDDBvJSrNwZO9IQ2dgqy\n",
      "    arguments(raw JSON string) = {\"a\":19,\"b\":3.7}\n",
      "\n",
      "â†’ Model requested tool calls:\n",
      "  - multiply({\"a\":1247,\"b\":83})  [call_id=call_59EkQjUlhuBV4MPWbYSSNzvL]\n",
      "  - divide({\"a\":19,\"b\":3.7})  [call_id=call_8MMWUDDBvJSrNwZO9IQ2dgqy]\n",
      "\n",
      "â†’ Executing tools locally (your server/app):\n",
      "  âœ“ multiply(**{'a': 1247, 'b': 83}) -> 103501\n",
      "  âœ“ divide(**{'a': 19, 'b': 3.7}) -> 5.135135135135135\n",
      "\n",
      "â†’ Sending tool outputs back to the model:\n",
      "{'type': 'function_call_output', 'call_id': 'call_59EkQjUlhuBV4MPWbYSSNzvL',\n",
      "'output': '{\"ok\": true, \"result\": 103501}'}\n",
      "{'type': 'function_call_output', 'call_id': 'call_8MMWUDDBvJSrNwZO9IQ2dgqy',\n",
      "'output': '{\"ok\": true, \"result\": 5.135135135135135}'}\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ROUND 2: Model response items\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "[0] type = function_call\n",
      "    name     = add\n",
      "    call_id  = call_xA8WxRJ1XcCJhjODGXTQ87Rz\n",
      "    arguments(raw JSON string) = {\"a\":103501,\"b\":5.135135135135135}\n",
      "\n",
      "â†’ Model requested tool calls:\n",
      "  - add({\"a\":103501,\"b\":5.135135135135135})  [call_id=call_xA8WxRJ1XcCJhjODGXTQ87Rz]\n",
      "\n",
      "â†’ Executing tools locally (your server/app):\n",
      "  âœ“ add(**{'a': 103501, 'b': 5.135135135135135}) -> 103506.13513513513\n",
      "\n",
      "â†’ Sending tool outputs back to the model:\n",
      "{'type': 'function_call_output', 'call_id': 'call_xA8WxRJ1XcCJhjODGXTQ87Rz',\n",
      "'output': '{\"ok\": true, \"result\": 103506.13513513513}'}\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ROUND 3: Model response items\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "[0] type = message\n",
      "    content = [ResponseOutputText(annotations=[], text='Result: 103506.13513513513 (approximately)\\n\\nNotes:\\n- Exact value is 3,829,727/37, which equals 103,506.135135135135... repeating.\\n- Approximate to 6 decimal places: 103506.135135.', type='output_text', logprobs=[])]\n",
      "\n",
      "âœ… No function calls. Final assistant text:\n",
      "Result: 103506.13513513513 (approximately)\n",
      "\n",
      "Notes:\n",
      "- Exact value is 3,829,727/37, which equals 103,506.135135135135... repeating.\n",
      "- Approximate to 6 decimal places: 103506.135135.\n"
     ]
    }
   ],
   "source": [
    "# Adding more tools doesn't change the model's behavior if the question doesn't require them\n",
    "\n",
    "add_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"add\",\n",
    "    \"description\": \"Add two numbers together and return the sum.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "sub_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"subtract\",\n",
    "    \"description\": \"Subtract two numbers and return the difference.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "mul_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"multiply\",\n",
    "    \"description\": \"Multiply two numbers together and return the product.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "\n",
    "div_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"divide\",\n",
    "    \"description\": \"Divide two numbers and return the answer.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"Numerator (dividend)\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Denominator (divisor)\"},\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract(a, b):\n",
    "    return a - b\n",
    "\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        return \"Error: Division by zero\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "DISPATCH = {\n",
    "    \"add\": add,\n",
    "    \"subtract\": subtract,\n",
    "    \"multiply\": multiply,\n",
    "    \"divide\": divide,\n",
    "}\n",
    "\n",
    "TOOLS = [add_tool, sub_tool, mul_tool, div_tool]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DEV_POLICY = \"Use the tools for any math. Never compute math yourself.\"\n",
    "\n",
    "def answer_with_math_tools_verbose(user_question: str) -> str:\n",
    "    print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "    print(\"START: User question\")\n",
    "    print(\"  \", user_question)\n",
    "    print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "    # Round 1: seed conversation with developer policy + user question\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=[\n",
    "            {\"role\": \"developer\", \"content\": DEV_POLICY},\n",
    "            {\"role\": \"user\", \"content\": user_question},\n",
    "        ],\n",
    "        tools=TOOLS\n",
    "    )\n",
    "\n",
    "    round_num = 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "        print(f\"ROUND {round_num}: Model response items\")\n",
    "        print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "\n",
    "        # Show every output item type\n",
    "        for i, item in enumerate(resp.output):\n",
    "            print(f\"[{i}] type = {item.type}\")\n",
    "\n",
    "            if item.type == \"function_call\":\n",
    "                print(f\"    name     = {item.name}\")\n",
    "                print(f\"    call_id  = {item.call_id}\")\n",
    "                print(f\"    arguments(raw JSON string) = {item.arguments}\")\n",
    "\n",
    "            elif item.type == \"message\":\n",
    "                # Some SDKs represent assistant text as message items\n",
    "                # output_text is the easiest way to get the final combined text.\n",
    "                try:\n",
    "                    print(f\"    content = {item.content}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        calls = [item for item in resp.output if item.type == \"function_call\"]\n",
    "\n",
    "        # If no tool calls, weâ€™re done; return final user-facing text\n",
    "        if not calls:\n",
    "            print(\"\\nâœ… No function calls. Final assistant text:\")\n",
    "            print(resp.output_text)\n",
    "            return resp.output_text\n",
    "\n",
    "        print(\"\\nâ†’ Model requested tool calls:\")\n",
    "        for call in calls:\n",
    "            print(f\"  - {call.name}({call.arguments})  [call_id={call.call_id}]\")\n",
    "\n",
    "        # Execute all calls and prepare tool outputs\n",
    "        tool_outputs = []\n",
    "        print(\"\\nâ†’ Executing tools locally (your server/app):\")\n",
    "        for call in calls:\n",
    "            fn = DISPATCH.get(call.name)\n",
    "            args = json.loads(call.arguments)\n",
    "\n",
    "            try:\n",
    "                result = fn(**args)\n",
    "                payload = {\"ok\": True, \"result\": result}\n",
    "                print(f\"  âœ“ {call.name}(**{args}) -> {result}\")\n",
    "            except Exception as e:\n",
    "                payload = {\"ok\": False, \"error\": str(e)}\n",
    "                print(f\"  âœ— {call.name}(**{args}) -> ERROR: {e}\")\n",
    "\n",
    "            tool_outputs.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": call.call_id,\n",
    "                # output is a string; keep it JSON for readability + structure\n",
    "                \"output\": json.dumps(payload),\n",
    "            })\n",
    "\n",
    "        print(\"\\nâ†’ Sending tool outputs back to the model:\")\n",
    "        for out in tool_outputs:\n",
    "            pretty_print(out)\n",
    "\n",
    "        # Continue conversation, ONLY sending tool outputs (chained with previous_response_id)\n",
    "        resp = client.responses.create(\n",
    "            model=MODEL,\n",
    "            previous_response_id=resp.id,\n",
    "            input=tool_outputs,\n",
    "            tools=TOOLS,\n",
    "            reasoning={\"effort\": \"minimal\"},\n",
    "        )\n",
    "\n",
    "        round_num += 1\n",
    "\n",
    "# Example\n",
    "final_text = answer_with_math_tools_verbose(\"What is 1247 * 83 + 19 / 3.7?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d2c83",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.5 Â· Quick Recap\n",
    "\n",
    "| Without function calling | With function calling |\n",
    "|---|---|\n",
    "| \"The weather is probably around 25Â°C\" | Calls `get_weather(\"Tel Aviv\")` â†’ gets **real** 28Â°C |\n",
    "| \"1247 Ã— 83 = 103,501\" (maybe wrong) | Calls `compute_math(\"1247*83+19/3.7\")` â†’ gets **exact** answer |\n",
    "| \"I can't send emails\" | Calls `send_email(to=\"john@...\", body=\"...\")` â†’ email **actually sent** |\n",
    "\n",
    "**The model's job changed:** instead of *pretending to know everything*, it now *decides which tool to call and with what arguments*. Your code does the rest.\n",
    "\n",
    "### Responses API vs Chat Completions â€” what changed?\n",
    "\n",
    "We're using the **Responses API** (`client.responses.create`) throughout this notebook â€” it's OpenAI's recommended API going forward.\n",
    "\n",
    "| Chat Completions (old) | Responses API (new) |\n",
    "|---|---|\n",
    "| `client.chat.completions.create()` | `client.responses.create()` |\n",
    "| `messages=[{role, content}]` | `input=[{role, content}]` or just a string |\n",
    "| System message in `messages` | `instructions=\"...\"` parameter |\n",
    "| `response.choices[0].message.content` | `response.output_text` |\n",
    "| `response.choices[0].message.tool_calls` | `response.output` items with `type==\"function_call\"` |\n",
    "| Tool result: `{role:\"tool\", tool_call_id:..., content:...}` | `{type:\"function_call_output\", call_id:..., output:...}` |\n",
    "| `response_format={type:\"json_schema\",...}` | `text={format:{type:\"json_schema\",...}}` |\n",
    "\n",
    "Now let's build something more interesting â€” starting with a proper calculator tool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22716c8b",
   "metadata": {},
   "source": [
    "# create a tool of weather API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac71e60",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
